# RepRL
Representation-Driven Reinforcement Learning 
<p align="center"> 
    <img src=figs/RepRL.pdf  height="400">
</p>

Code is based on the code provided by "Simple random search provides a competitive approach to reinforcement learning" (Mania et al.) at https://github.com/modestyachts/ARS/tree/master.
The code for the Deep Weight Space architecture was taken from the code provided by "Equivariant Architectures for Learning in Deep Weight Spaces" (Navon et al.) at https://github.com/AvivNavon/DWSNets. 


## Citation
If you find our work or this code to be useful in your own research, please consider citing the following paper:

```bib

@InProceedings{pmlr-v202-nabati23a,
  title = 	 {Representation-Driven Reinforcement Learning},
  author =       {Nabati, Ofir and Tennenholtz, Guy and Mannor, Shie},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {25588--25603},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/nabati23a/nabati23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/nabati23a.html},
}

```


